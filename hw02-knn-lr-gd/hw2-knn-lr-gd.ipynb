{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в анализ данных, ИАД-2\n",
    "\n",
    "## НИУ ВШЭ, 2019-20 учебный год"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание выполнил(а): _(впишите свои фамилию и имя)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Дата выдачи:__ 04.03.2020\n",
    "\n",
    "__Дедлайн:__ 23:59 17.03.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\text{points} \\times 10 / 16,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за обязательную часть, которое вы набрали. Максимальное число баллов, которое можно получить за обязательную часть — 16, а максимальное число дополнительных баллов, которые пойдут в бонус — 2 (в бонус идет только целое число баллов). Бонусные задания отмечены звездочками (*).\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формат сдачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-6: rd5CNrr\n",
    "\n",
    "Перед отправкой перезагрузите ноутбук и проверьте, что все ячейки могут быть последовательно выполнены. Ноутбук должен запускаться с использованием python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN своими руками (5 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте две функции расстояния (1 балл)\n",
    "- Евклидова метрика\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_2 = \\sqrt{\\sum\\limits_{j=1}^n\\left(x_{(i)}^j - x^j\\right)^2}\\qquad\\text{(0.5 балла)}\n",
    "$$\n",
    "- метрика Манхэттена\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_1 = \\sum\\limits_{j=1}^n\\left|x_{(i)}^j - x^j\\right|\\qquad\\text{(0.5 балла)}\n",
    "$$\n",
    "Обе функции должны на вход получать матрицу `np.array of shape(n, m)` и вектор `np.array of shape(m, )`, а возвращать вектор расстояний от каждой строчки матрицы до вектора `np.array of shape(n, )`\n",
    "\n",
    "**В данном пункте запрещено использование циклов for, while. Пользуйтесь возможностями numpy.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_metric(X, x):\n",
    "    distances = np.apply_along_axis(lambda l: l - x, 1, X)\n",
    "    distances = np.apply_along_axis(lambda x: np.power(np.sum(x ** 2), 0.5), 1, distances)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_metric(X, x):\n",
    "    distances = np.apply_along_axis(lambda l: l - x, 1, X)\n",
    "    distances = np.apply_along_axis(lambda x: np.sum(np.absolute(x)), 1, distances)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3], [5, 6, 7], [8, 9, 10]])\n",
    "y = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(euclidian_metric(X, y), np.array([ 2.23606798,  8.77496439, 13.92838828]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(manhattan_metric(X, y), np.array([ 3., 15., 24.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте алгоритм kNN для регрессии (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте взвешенный алгоритм kNN для регрессии. Пусть нам нужно вычислить значение $y$ для некоторого $x$ при известных данных $\\left(x_1, y_1\\right), \\ldots, \\left(x_\\ell, y_\\ell\\right)$. Предсказанием вашего регрессора будет являться\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{\\sum\\limits_{i=1}^kw_iy_{(i)}}{\\sum\\limits_{i=1}^kw_i},\n",
    "$$\n",
    "где $\\left(x_{(1)}, y_{(1)}\\right), \\ldots, \\left(x_{(k)}, y_{(k)}\\right)$ - ближайшие $k$ объектов к $x$ по некоторой метрике $d(\\cdot, \\cdot)$. Ваш алгоритм должен уметь работать с двумя метриками:\n",
    "\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_2 = \\sqrt{\\sum\\limits_{j=1}^n\\left(x_{(i)}^j - x^j\\right)^2}\\qquad\\text{(евклидова)}\n",
    "$$\n",
    "$$\n",
    "d\\left(x_{(i)}, x\\right) = \\|x_{(i)} - x\\|_1 = \\sum\\limits_{j=1}^n\\left|x_{(i)}^j - x^j\\right|\\qquad\\text{(манхэттена)}\n",
    "$$\n",
    "\n",
    "- Реалиуйте данный класс для равномерных весов (то есть $w_i = \\frac{1}{k}$) (__3 балла__)\n",
    "- Реалиуйте возможность передать данному классу параметр `weights='distance'`, чтобы реализовывался взвешенный алгоритм kNN с весами, обратными расстояниям (то есть $w_i = \\frac{1}{d\\left(x, x_{(i)}\\right)}$, где $d(x, y)$ - функция расстояния) (__1 балл__)\n",
    "\n",
    "В данном классе должны быть реализованы методы `.fit` и `.predict`. Однако, для удобства может оказаться полезным реализовать еще некоторые вспомогательные методы, например, функции расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, metric='euclid', k=5, weights='uniform'):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        metric ('euclid' or 'manhattan')\n",
    "        k - number of nearest neighbors\n",
    "        \"\"\"\n",
    "        \n",
    "        self.metric = metric\n",
    "        self.k = k\n",
    "        self.weights = weights\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_train - np.array of shape (l, d)\n",
    "        y_train - np.array of shape (l,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_test - np.array of shape (m, d)\n",
    "        \n",
    "        OUTPUT:\n",
    "        y_pred - np.array of shape (m,)\n",
    "        \"\"\"\n",
    "        # your code here         \n",
    "        if self.metric == 'euclid':\n",
    "            distances = np.apply_along_axis(lambda x: euclidian_metric(self.X_train, x), 1, X_test)\n",
    "        elif self.metric == 'manhattan':\n",
    "            distances = np.apply_along_axis(lambda x: manhattan_metric(self.X_train, x), 1, X_test)\n",
    "        idx = np.apply_along_axis(lambda x: np.argpartition(x, self.k)[:self.k], 1, distances)\n",
    "        if self.weights == 'uniform':\n",
    "            y_pred = np.apply_along_axis(lambda x: np.mean(y_train[x]), 1, idx)\n",
    "        elif self.weights == 'distance':\n",
    "            distance_weights = np.apply_along_axis(lambda x: 1 / x[np.argpartition(x, self.k)[:self.k]], 1, distances)\n",
    "            nearest_y = np.apply_along_axis(lambda x: y_train[x], 1, idx)\n",
    "            distance_weights_sum = np.tile(np.apply_along_axis(np.sum, 1, distance_weights), (self.k, 1))\n",
    "            y_pred = nearest_y * distance_weights\n",
    "            y_pred = np.apply_along_axis(np.sum, 1, y_pred)\n",
    "            y_pred = y_pred / distance_weights_sum\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверим, что наш knn и соответствующий knn из sklearn выдает одинаковые (ну, или почти одинаковые) результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17032019)\n",
    "X_train = np.random.randn(1000, 50)\n",
    "y_train = np.random.randn(1000,)\n",
    "X_test = np.random.randn(500, 50)\n",
    "y_test = np.random.randn(500,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проверка для евклидовой метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(metric='euclid')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "sknn = KNeighborsRegressor(p=2, weights='uniform')\n",
    "sknn.fit(X_train, y_train)\n",
    "\n",
    "assert np.allclose(knn.predict(X_test), sknn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проверка для манхэттенской метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(metric='manhattan')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "sknn = KNeighborsRegressor(p=1, weights='uniform')\n",
    "sknn.fit(X_train, y_train)\n",
    "\n",
    "assert np.allclose(knn.predict(X_test), sknn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проверка для взвешенных весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(metric='euclid', weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "sknn = KNeighborsRegressor(p=2, weights='distance')\n",
    "sknn.fit(X_train, y_train)\n",
    "\n",
    "assert np.allclose(knn.predict(X_test), sknn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(metric='manhattan', weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "sknn = KNeighborsRegressor(p=1, weights='distance')\n",
    "sknn.fit(X_train, y_train)\n",
    "\n",
    "assert np.allclose(knn.predict(X_test), sknn.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия своими руками (5 баллов)\n",
    "\n",
    "Реализуйте линейную регрессию с градиентным спуском для [функции потерь Хьюбера](https://en.wikipedia.org/wiki/Huber_loss):\n",
    "\n",
    "$$\n",
    "L_\\delta\\left(y, \\hat{y}\\right) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2}\\left(y - \\hat{y}\\right)^2, \\qquad &|y - \\hat{y}| \\leq \\delta\\\\\n",
    "\\delta\\left|y - \\hat{y}\\right| - \\frac{1}{2}\\delta^2,\\qquad & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "В таком случае общее значение функции потерь на всем датасете $(x_1, y_1), \\ldots, (x_\\ell, y_\\ell)$ будет равно\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{\\ell}\\sum\\limits_{i=1}^\\ell L_\\delta\\left(y_i, \\hat{y}_i\\right)\n",
    "$$\n",
    "\n",
    "Чему будет равна производная данной функции по $\\hat{y}$?\n",
    "\n",
    "__Вспомните, что такое вектор $\\hat{y}$? Как он зависит от $X$ и $w$?__\n",
    "\n",
    "Проверьте работу вашего метода: выведите результаты его работы на той же искусственной выборке, что и в задаче выше (в качестве метрик качества используйте MSE и Huber loss). Постройте график зависимости значения функции потерь от итерации градиентного спуска.\n",
    "\n",
    "*Вы можете опустить единичный признак в модели и не добавлять его в данные. Для данной искусственной выборки это не актуально, потому что целевая переменная в этом случае является случайной величиной из стандартного нормального распределения со средним 0.*\n",
    "\n",
    "*Вектор весов в градиентном спуске можете инициализировать нулями.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти ссылки могут показаться вам полезными:\n",
    "- https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/lecture02-linregr.pdf\n",
    "- https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931\n",
    "- https://stats.stackexchange.com/questions/312737/mean-absolute-error-mae-derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте функцию потерь Хьюбера для одного примера и ее градиент по весам (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(x, y, w, delta):\n",
    "    \"\"\"\n",
    "    x - np.array shape=(d,)\n",
    "    y - scalar\n",
    "    w - np.array shape=(d,)\n",
    "    delta - scalar\n",
    "    \n",
    "    OUTPUT:\n",
    "    loss - scalar\n",
    "    \"\"\"\n",
    "    Y = x @ w\n",
    "    if np.abs(y - Y) <= delta:\n",
    "        loss = 1 / 2 * (y - Y) ** 2\n",
    "    else:\n",
    "        loss = delta * np.abs(y - Y) - 1 / 2 * delta ** 2\n",
    "        \n",
    "    return loss\n",
    "\n",
    "def huber_grad(x, y, w, delta):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "    x - np.array shape=(d,)\n",
    "    y - scalar\n",
    "    w - np.array shape=(d,)\n",
    "    delta - scalar\n",
    "    \n",
    "    OUTPUT:\n",
    "    grad - np.array shape=(d,)\n",
    "    \"\"\"\n",
    "    Y = x @ w\n",
    "    \n",
    "    if np.abs(y - Y) <= delta:\n",
    "        grad = (y - Y) * -x\n",
    "    else:\n",
    "        grad = np.sign(y - Y) * -x\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшие проверки для вашего удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "w = np.array([3, 5, 12])\n",
    "y = 19\n",
    "delta = 1\n",
    "\n",
    "assert huber_loss(x, y, w, delta) == 29.5\n",
    "assert np.allclose(huber_grad(x, y, w, delta), np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "w = np.array([3, 5, 12])\n",
    "y = 49.2\n",
    "delta = 1\n",
    "\n",
    "assert np.allclose(huber_loss(x, y, w, delta), 0.02000000000000057)\n",
    "assert np.allclose(huber_grad(x, y, w, delta), np.array([-0.2, -0.4, -0.6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так будет выглядеть график нашей функции потерь. Можете (это не обязательное требование) проверить, что ваш результат будет выглядеть так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь уже и саму линейную регрессию (4 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionHuber:\n",
    "    def __init__(self, delta=1.0, max_iter=1000, tol=1e-6, eta=1e-2):\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        delta - scalar in Huber loss\n",
    "        max_iter - maximum possible number of iterations in Gradient Descent\n",
    "        tol - precision for stopping criterion in Gradient Descent\n",
    "        eta - step size in Gradient Descent (learning rate)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.delta = delta\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.eta = eta\n",
    "        \n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_train - np.array of shape (l, d)\n",
    "        y_train - np.array of shape (l,)\n",
    "        \n",
    "        В этой функции вы должны инициализировать веса нулями, а также \n",
    "        итерационно обновлять веса с помощью \n",
    "        градиентного спуска (считать и запоминать лосс на каждой итерации тоже будет неплохо)\n",
    "        \"\"\"\n",
    "        self.w = np.zeros(X_train.shape[1])\n",
    "        self.loss_history = [self.calc_loss(X_train, y_train)]\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            grad = self.calc_gradient(X_train, y_train)\n",
    "            \n",
    "            w_new = self.w - self.eta * grad\n",
    "            \n",
    "            loss = self.calc_loss(X_train, y_train)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            if np.linalg.norm(self.w - w_new) <= self.tol:\n",
    "                w = self.w_new\n",
    "                break\n",
    "            \n",
    "            self.w = w_new\n",
    "        \n",
    "        return self.loss_history\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        X_test - np.array of shape (m, d)\n",
    "        \n",
    "        OUTPUT:\n",
    "        y_pred - np.array of shape (m,)\n",
    "        \n",
    "        Просто предсказать ответы с помощью обученных весов\n",
    "        \"\"\"\n",
    "        y_pred = X_test @ self.w\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the gradient of Huber loss by weights.\n",
    "        \n",
    "        INPUT:\n",
    "        X - np.array of shape (l, d)\n",
    "        y - np.array of shape (l,)\n",
    "        \n",
    "        OUTPUT:\n",
    "        grad - np.array of shape (d,)\n",
    "        \n",
    "        Посчитайте градиент как среднее от градиентов для каждого примера\n",
    "        \"\"\"\n",
    "        grad = np.zeros_like(self.w)\n",
    "        \n",
    "        for x_i, y_i in zip(X, y):\n",
    "            grad += huber_grad(x_i, y_i, self.w, delta=1)\n",
    "        \n",
    "        grad /= X.shape[0]\n",
    "        return grad \n",
    "    \n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculates the Huber loss.\n",
    "        \n",
    "        INPUT:\n",
    "        X - np.array of shape (l, d)\n",
    "        y - np.array of shape (l,)\n",
    "        \n",
    "        OUTPUT:\n",
    "        loss - float\n",
    "        \n",
    "        Посчитайте loss по выборке как сумма loss'ов для каждого \n",
    "        примера, поделить на размер выборки\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for x_i, y_i in zip(X, y):\n",
    "            loss += huber_loss(x_i, y_i, self.w, delta=1)\n",
    "        \n",
    "        loss /= X.shape[0]\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegressionHuber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график зависимости функции потерь от итерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2849a303a90>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуйста, при использовании различных функций из библиотек импортируйте все, что вам понадобилось в данной части, в следующем блоке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectFromModel, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании вы поработаете с данными из другого соревнования на Kaggle: https://www.kaggle.com/c/house-prices-advanced-regression-techniques. Задача - предсказание цены дома."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли в данных пропуски? Если да, то для каждого столбца, в котором они имеются, посчитайте их количество и их долю от общего числа значений. Что вы наблюдаете? Избавьтесь от пропусков. Для каждого из примененных методов обоснуйте свое решение. **Проверьте, что вы действительно избавились от пропусков.**\n",
    "\n",
    "*Напоминание. В зависимости от типа столбца, можно заполнить пропуски, например, средним арифметическим, медианой, модой, можно какими-то отдельными значениями. А можно такие столбцы вообще удалить.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработайте категориальные признаки. В их обнаружении вам может помочь синтаксис `pandas` (например, можно обратить внимание на типы столбцов), а также описание датасета и его исследование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите и визуализируйте попарную корреляцию Пирсона между всеми признаками. Какие выводы можно сделать?\n",
    "\n",
    "*Для визуализации можно использовать `seaborn.heatmap()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите признаки с максимальным и минимальным **абсолютным** значением коэффициента корреляции Пирсона с предсказываемым значением. Изобразите на графиках зависимость найденных признаков от предсказываемого значения.\n",
    "\n",
    "*Не забудьте указать название графика и обозначить, что изображено по каждой из осей.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограмму распределения предсказываемого значения. Для избавления от разницы в масштабах, а также «смещения» распределения переменной в сторону нормального (что бывает полезно при статистическом анализе), можно прологарифмировать ее (это обратимое преобразование, поэтому целевую переменную легко восстановить). В данном случае воспользуйтесь `numpy.log1p`, чтобы сделать преобразование $y \\to \\ln\\left(1 + y\\right)$. Постройте гистограмму распределения от нового предсказываемого значения. Опишите наблюдения.\n",
    "\n",
    "*В дальнейшем используйте в качестве предсказываемого значения вектор, который получился после логарифмирования.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем непосредственно к построению моделей. Разобьем выборку на обучение и контроль.\n",
    "\n",
    "*Пожалуйста, **не меняйте** значение `random_state` в следующей ячейке.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data.drop('SalePrice', axis=1),\n",
    "                                                  np.log1p(data['SalePrice']), random_state=17032019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените к данным следующие алгоритмы:\n",
    "\n",
    "- kNN\n",
    "- линейная регрессия\n",
    "- Lasso\n",
    "- Ridge\n",
    "\n",
    "(Если вдруг забыли что такое Lasso и Ridge - https://habr.com/ru/post/328760/)\n",
    "\n",
    "Для каждого из методов подберите гиперпараметры с помощью кросс-валидации. Обучите алгоритмы с лучшими гиперпараметрами на обучающей выборке и оцените качество по метрике **Root** Mean Squared Error. Какой из методов показывает себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте гистограммы значений весов для линейной регрессии, Lasso и Ridge. Опишите наблюдения. В чем различия между полученными наборами весов и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добейтесь того, чтобы в заданиях выше ваш лучший алгоритм давал качество не больше 0.125 на тестовых данных по метрике RMSE (если вы дошли до этого задания, а качество выше уже удовлетворяет этому условию, вы автоматически получите за него полный балл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10* (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добейтесь того, чтобы в заданиях выше ваш лучший алгоритм давал качество не больше 0.121 на тестовых данных по метрике RMSE. Для этого вы можете использовать самые разные методы, какие захотите - отбор признаков, генерация новых, разные способы предобработки данных. Единственное ограничение - не использовать никакие алгоритмы регрессии, кроме kNN, линейной регрессии, Lasso и Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория (бонусная часть)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За данную часть можно получить бонусные баллы. Решения необходимо оформить в этом же файле в ячейках типа Markdown, пользуясь $\\LaTeX$ для записи математических формул."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите производную сигмоидной функции\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "и выразите ее через $\\sigma(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your solution here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2* (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите константу $C$, решающую следующую задачу ($0 < \\tau < 1$ фиксировано):\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{i=1}^\\ell\\rho_\\tau\\left(y_i - C\\right) \\to \\min_C,\n",
    "$$\n",
    "\n",
    "где\n",
    "\n",
    "$$\n",
    "\\rho_\\tau(z) =\n",
    "\\begin{cases}\n",
    "\\tau z, & z > 0\\\\\n",
    "(\\tau - 1)z, & z \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Вам может показаться полезной эта ссылка https://medium.com/@gennadylaptev/median-and-mae-3e85f92df2d7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your solution here)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
